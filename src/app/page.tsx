import * as cheerio from 'cheerio';

import 'server-only';

import {
  SystemMessagePromptTemplate,
  HumanMessagePromptTemplate,
  ChatPromptTemplate,
  PromptTemplate,
} from "langchain/prompts";
import { LLMChain } from "langchain/chains";
import { ChatOpenAI } from "langchain/chat_models/openai";
import { StructuredOutputParser } from "langchain/output_parsers";
import { z } from "zod";
import { cache } from 'react';

async function getIncorrectOpinions(): Promise<string[]> {
  const response = await fetch('https://www.correctopinions.info/', { next: { revalidate: 60 } });
  const html = await response.text();
  const $ = cheerio.load(html);
  const listItems = $('ol').first().find('li');
  const contents: string[] = [];
  listItems.each((index, element) => {
    contents.push($(element).text().trim());
  });
  return contents;
}

const getCorrectOpinions = cache(async (incorrectOpinion: string) => {
  const parser = StructuredOutputParser.fromZodSchema(
    z.object({
      correctedOpinion: z.string().describe('corrected opinion')
    })
  );
  const formatInstructions = parser.getFormatInstructions();

  const example = await new PromptTemplate({
    inputVariables: ["input", "output"],
    template: `
    Input: "{input}"
    Output: {{opinion: "{output}"}}
    `,
  }).format({
    input: "Color is good in UI",
    output: "Color has no place in UI"
  })

  const correctionPrompt = await ChatPromptTemplate.fromPromptMessages([
    SystemMessagePromptTemplate.fromTemplate(
      `
      You are CorrectedOpinions Bot.
      You will be given an incorrect opinion which you are to believe is very incorrect. 
      For the opinion provided, you will provide the opposite opinion as the "corrected opinion". 
      Avoid weak words like sometime and maybe. They may be controversial.

      {formatInstructions}

      {example}
      `
    ),
    HumanMessagePromptTemplate.fromTemplate('"{incorrectOpinion}"'),
  ]).partial({ example, formatInstructions })

  const chat = new ChatOpenAI({ temperature: 0, modelName: "gpt-4" });
  const chain = new LLMChain({ prompt: correctionPrompt, llm: chat, outputParser: parser, outputKey: 'correctedOpinion' })
  const response = (await chain.predict({ incorrectOpinion })).correctedOpinion;
  return response;
});

export default async function Home() {
  const incorrectOpinions = await getIncorrectOpinions();
  const claims = (await Promise.all(incorrectOpinions.map(opinion => getCorrectOpinions(opinion)))).flatMap(value => value)

  return (
    <div className="min-h-screen">
      <header className="py-16">
        <h1 className="text-center font-light	text-4xl md:text-5xl lg:text-6xl">
          Corrected Opinions
        </h1>
        <h2 className="text-center font-light	text-2xl md:text-3xl lg:text-4xl">
          LLM Edition*
        </h2>
      </header>
      <main className="max-w-7xl mx-auto md:px-12 py-6">
        <div className='px-1 md:px-2 lg:px-3'>
          <div className='px-2 mx-5'>
            <ol className='list-decimal list-inside	text-base'>
              {
                claims.map(claim => (
                  <li key={claim} className='mt-1.5 first:mt-0'>{claim}</li>
                ))
              }
            </ol>
            <p className='pt-2'>
              *The opinions on this page are generated by an LLM negating the generally bad
              takes on <a href="https://correctopinions.info" target='_blank'>correctopinions.info</a>.
              They do not necessarily represent the views of the app author (but they probably do).
            </p>
          </div>
        </div>
      </main>
    </div>
  )
}